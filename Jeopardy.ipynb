{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Patterns in Jeopardy Questions\n",
    "### Practice with Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Show Number    Air Date      Round                         Category  Value  \\\n",
      "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
      "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
      "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
      "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
      "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
      "\n",
      "                                            Question      Answer  \n",
      "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
      "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
      "2  The city of Yuma in this state has a record av...     Arizona  \n",
      "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
      "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  \n",
      "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
      "       ' Question', ' Answer'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "jeopardy = pd.read_csv(\"jeopardy.csv\")\n",
    "\n",
    "# Explore the dataset\n",
    "print(jeopardy.head(5))\n",
    "print(jeopardy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question',\n",
      "       'Answer'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Rename columns to get rid of spaces in front\n",
    "# Not the best way but the small number of columns does not warrant a more\n",
    "# sophisticated solution\n",
    "\n",
    "jeopardy.rename(columns = {\n",
    "        \" Air Date\": \"Air Date\", \" Round\": \"Round\", \" Category\": \"Category\", \" Value\": \"Value\", \" Question\": \"Question\", \" Answer\": \"Answer\"\n",
    "    }, inplace = True)\n",
    "print(jeopardy.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>clean_question</th>\n",
       "      <th>clean_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "      <td>for the last 8 years of his life galileo was u...</td>\n",
       "      <td>copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "      <td>no 2 1912 olympian football star at carlisle i...</td>\n",
       "      <td>jim thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>the city of yuma in this state has a record av...</td>\n",
       "      <td>arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>in 1963 live on the art linkletter show this c...</td>\n",
       "      <td>mcdonalds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "      <td>signer of the dec of indep framer of the const...</td>\n",
       "      <td>john adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question      Answer  \\\n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus   \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe   \n",
       "2  The city of Yuma in this state has a record av...     Arizona   \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's   \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams   \n",
       "\n",
       "                                      clean_question clean_answer  \n",
       "0  for the last 8 years of his life galileo was u...   copernicus  \n",
       "1  no 2 1912 olympian football star at carlisle i...   jim thorpe  \n",
       "2  the city of yuma in this state has a record av...      arizona  \n",
       "3  in 1963 live on the art linkletter show this c...    mcdonalds  \n",
       "4  signer of the dec of indep framer of the const...   john adams  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "def normalize_text(some_string):\n",
    "    lowercase_string = some_string.lower()\n",
    "    punc_dict = {}\n",
    "    for punc in string.punctuation:\n",
    "        punc_dict[punc] = None\n",
    "    # Puts punctuation into a dictionary, each punctuation having None associated\n",
    "    final_string = lowercase_string.translate(str.maketrans(punc_dict))\n",
    "    # maketrans turns punctuation dictionary into a translation table that can be read by the tronslate method\n",
    "    return final_string\n",
    "\n",
    "\n",
    "\n",
    "jeopardy[\"clean_question\"] = jeopardy[\"Question\"].apply(normalize_text)\n",
    "jeopardy[\"clean_answer\"] = jeopardy[\"Answer\"].apply(normalize_text)\n",
    "\n",
    "jeopardy[jeopardy.columns[5:9]].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Normalizing Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def num_dollar(some_string):\n",
    "    punc_dict = {}\n",
    "    for punc in string.punctuation:\n",
    "        punc_dict[punc] = None\n",
    "    no_punc_dollar = some_string.translate(str.maketrans(punc_dict))\n",
    "    try:\n",
    "        final_dollar = int(no_punc_dollar)\n",
    "    except Exception:\n",
    "        final_dollar = 0\n",
    "    return final_dollar\n",
    "\n",
    "jeopardy[\"clean_value\"] = jeopardy[\"Value\"].apply(num_dollar)\n",
    "\n",
    "jeopardy[\"Air Date\"] = pd.to_datetime(jeopardy[\"Air Date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarities between Answers and Questions\n",
    "Now that our data has been cleaned so that it is easy to work with, let's consider how we might approach Jeopardy with this information in hand. We can ask two questions:\n",
    "1. How often does the answer show up in the question itself?\n",
    "2. How often are questions recycled?\n",
    "\n",
    "These two questions can help inform our study strategy for an edge in Jeopardy. Let's look at the first question.\n",
    "\n",
    "### Answers in Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average fraction of words shared in both the question and the answer:\n",
      "0.0603527738547\n"
     ]
    }
   ],
   "source": [
    "def match_count(jeo_row):\n",
    "    split_answer = jeo_row[\"clean_answer\"].split(\" \")\n",
    "    split_question = jeo_row[\"clean_question\"].split(\" \")\n",
    "    if \"the\" in split_answer:\n",
    "        split_answer.remove(\"the\")\n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "    match_count = 0\n",
    "    for item in split_answer:\n",
    "        if item in split_question:\n",
    "            match_count += 1\n",
    "    return match_count / len(split_answer)\n",
    "\n",
    "jeopardy[\"answer_in_question\"] = jeopardy.apply(match_count, axis = 1)\n",
    "\n",
    "\n",
    "print(\"Average fraction of words shared in both the question and the answer:\")\n",
    "print(jeopardy[\"answer_in_question\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that on average, around 6 percent of the words in Jeopardy questions show up in the answers. If I were to study for Jeopardy, it does not seem prudent to rely on arriving at an answer based on looking at the question. However, if I were to come across as a stumper, this finding suggests that a key word to the answer is possibly in the question and it may be a good starting point when I have nothing else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recycled Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average fraction of major terms reused from older questions:\n",
      "0.687124288097\n"
     ]
    }
   ],
   "source": [
    "question_overlap = []\n",
    "terms_used = set()\n",
    "jeopardy = jeopardy.sort_values(\"Air Date\")\n",
    "\n",
    "for i, row in jeopardy.iterrows(): #iterrows gives index i and row\n",
    "        split_question = row[\"clean_question\"].split(\" \")\n",
    "        split_question = [q for q in split_question if len(q) > 5]\n",
    "        match_count = 0\n",
    "        for word in split_question:\n",
    "            if word in terms_used:\n",
    "                match_count += 1\n",
    "        for word in split_question:\n",
    "            terms_used.add(word)\n",
    "        if len(split_question) > 0:\n",
    "            match_count = match_count / len(split_question)\n",
    "        question_overlap.append(match_count)\n",
    "jeopardy[\"question_overlap\"] = question_overlap\n",
    "\n",
    "print(\"Average fraction of major terms reused from older questions:\")\n",
    "print(jeopardy[\"question_overlap\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests that around 69% of questions are similar to older ones in terms used. While this doesn't tell us if the questions are recycled, since we aren't looking at phrases, it does tell us that many of the terms involved are similar so the topics are likely to not vary widely overtime. Studying old questions is likely a very beneficial way to get an edge in Jeopardy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-Squared Test for Low and High Value Questions\n",
    "\n",
    "While this has been helpful, the next step in making the data work for us is to identify which words appear often in high value questions so that we can focus our efforts on those. We'll define high value as being worth greater than $800."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def high_or_low(row):\n",
    "    if row[\"clean_value\"] > 800:\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "    return value\n",
    "\n",
    "jeopardy[\"high_value\"] = jeopardy.apply(high_or_low, axis = 1)\n",
    "\n",
    "def high_val_word(word):\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    for i, row in jeopardy.iterrows():\n",
    "        split_question = row[\"clean_question\"].split(\" \")\n",
    "        if word in split_question:\n",
    "            if row[\"high_value\"] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    return high_count, low_count\n",
    "\n",
    "observed_expected = []\n",
    "terms_used = list(terms_used)\n",
    "comparison_terms = terms_used[0:5]\n",
    "\n",
    "for term in comparison_terms:\n",
    "    observed_expected.append(high_val_word(term))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0), (0, 1), (0, 5), (1, 0), (0, 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_expected \n",
    "# each tuple shows how many times a certain term was in a high value question, \n",
    "# followed by times in a low value question\n",
    "# each tuple is a different word\n",
    "\n",
    "# These are all observed values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=4.9755842343913503, pvalue=0.025707519787911092),\n",
       " Power_divergenceResult(statistic=0.40196284612688399, pvalue=0.52607729857054686),\n",
       " Power_divergenceResult(statistic=2.00981423063442, pvalue=0.1562844540498966),\n",
       " Power_divergenceResult(statistic=2.4877921171956752, pvalue=0.11473257634454047),\n",
       " Power_divergenceResult(statistic=0.40196284612688399, pvalue=0.52607729857054686)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating Chi-Squared\n",
    "from scipy.stats import chisquare\n",
    "import numpy as np\n",
    "\n",
    "high_value_count = len(jeopardy[jeopardy[\"high_value\"] == 1])\n",
    "low_value_count = len(jeopardy[jeopardy[\"high_value\"] == 0])\n",
    "\n",
    "chi_squared = []\n",
    "\n",
    "for some_list in observed_expected:\n",
    "    total = sum(some_list)\n",
    "    total_prop = total / len(jeopardy)\n",
    "    exp_term_count_high = total_prop * high_value_count\n",
    "    exp_term_count_low = total_prop * low_value_count\n",
    "    \n",
    "    observed = np.array([some_list[0], some_list[1]])\n",
    "    expected = np.array([exp_term_count_high, exp_term_count_low])\n",
    "    \n",
    "    chi_squared.append(chisquare(observed, expected))\n",
    "\n",
    "# Taking the first tuple (2, 0) as an example\n",
    "# We add the high and low counts, 2 + 0 = 2. \n",
    "# This word has appeared a total of 2 times in a question in the jeopardy data\n",
    "# Divide that by length of jeopardy to get the proportion of ?'s that \n",
    "# word has appeard in\n",
    "# If that word appears in 4% of the questions, and there are 30 high_value_?'s\n",
    "# then we expect to the term to appear in (total_prop * high_value_count) number\n",
    "# of questions.\n",
    "# The same goes for low value questions.\n",
    "# However, our observed values are the original tuple. They were gathered\n",
    "# by actually comparing with every question.\n",
    "# Our chisquare fn takes the observed, then the expected, then gives us\n",
    "# chisq and p\n",
    "\n",
    "chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-Squared Results\n",
    "\n",
    "The first thing to note is that our values for observed_expected were all very low, with many in the range of 0 to 2 and one value 5. This makes the Chi-Squared Test less applicable and the results should be considered carefully.\n",
    "\n",
    "All but the first of our p-values indicate there is no statistically significant discrepancy between high and low values. Only the first one has a p-value less than 0.05, but again the tuple being considered only had a total count of 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going Further\n",
    "\n",
    "For future analysis, there are a number of things to make our analysis more sophisticated:\n",
    "\n",
    "1. Instead of choosing significant words based on length, we could manually make of list of articles and similar words (the, a, than, of, etc.).\n",
    "2. Perform the Chi-Squared test with more terms (the code is slow so this will take a while!)\n",
    "3. Consider categories with the Category column\n",
    "4. This data was just a subset of the whole data, we can expand to the complete data.\n",
    "5. Consider phrases instead of single words to get a better idea of question overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
